# ğŸ† KSIE ëŒ€í•™ìƒ í”„ë¡œì íŠ¸ ê²½ì§„ëŒ€íšŒ

**í•œêµ­ê²½ì˜ì‹œìŠ¤í…œí•™íšŒ ëŒ€í•™ìƒ í”„ë¡œì íŠ¸ ê²½ì§„ëŒ€íšŒ - ì €ì¶œì‚° ë¬¸ì œ ë¶„ì„ ë° í•´ê²° ë°©ì•ˆ ì œì‹œ**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Machine Learning](https://img.shields.io/badge/ML-Scikit--learn-orange.svg)](https://scikit-learn.org)
[![Data Analysis](https://img.shields.io/badge/Analysis-Pandas-green.svg)](https://pandas.pydata.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“‹ ëª©ì°¨

- [í”„ë¡œì íŠ¸ ê°œìš”](#-í”„ë¡œì íŠ¸-ê°œìš”)
- [ë¬¸ì œ ì •ì˜](#-ë¬¸ì œ-ì •ì˜)
- [ë°ì´í„° ë¶„ì„](#-ë°ì´í„°-ë¶„ì„)
- [ëª¨ë¸ë§](#-ëª¨ë¸ë§)
- [ì£¼ìš” ê²°ê³¼](#-ì£¼ìš”-ê²°ê³¼)
- [ê¸°ìˆ  ìŠ¤íƒ](#-ê¸°ìˆ -ìŠ¤íƒ)
- [ì„¤ì¹˜ ë° ì‹¤í–‰](#-ì„¤ì¹˜-ë°-ì‹¤í–‰)
- [í”„ë¡œì íŠ¸ êµ¬ì¡°](#-í”„ë¡œì íŠ¸-êµ¬ì¡°)
- [ì‚¬ìš©ë²•](#-ì‚¬ìš©ë²•)
- [ê¸°ì—¬í•˜ê¸°](#-ê¸°ì—¬í•˜ê¸°)

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

ë³¸ í”„ë¡œì íŠ¸ëŠ” **í•œêµ­ê²½ì˜ì‹œìŠ¤í…œí•™íšŒ ëŒ€í•™ìƒ í”„ë¡œì íŠ¸ ê²½ì§„ëŒ€íšŒ**ì— ì¶œí’ˆëœ ì‘í’ˆìœ¼ë¡œ, í•œêµ­ì˜ ì‹¬ê°í•œ ì €ì¶œì‚° ë¬¸ì œë¥¼ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ê´€ì ì—ì„œ ë¶„ì„í•˜ê³  í•´ê²° ë°©ì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤.

### í•µì‹¬ ëª©í‘œ

- ğŸ“Š **ë°ì´í„° ê¸°ë°˜ ë¶„ì„**: ì§€ì—­ë³„ ì¶œì‚°ìœ¨ ì°¨ì´ì˜ ì›ì¸ ë¶„ì„
- ğŸ¤– **ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§**: ì¶œì‚°ìœ¨ ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ
- ğŸ“° **í…ìŠ¤íŠ¸ ë§ˆì´ë‹**: ë‰´ìŠ¤ ë°ì´í„°ë¥¼ í†µí•œ ì¶œì‚°ì‹¬ë¦¬ì§€ìˆ˜ ì‚°ì¶œ
- ğŸ’¡ **ì •ì±… ì œì•ˆ**: ë°ì´í„° ê¸°ë°˜ì˜ ì‹¤ìš©ì  í•´ê²° ë°©ì•ˆ ì œì‹œ

## ğŸš¨ ë¬¸ì œ ì •ì˜

### ì €ì¶œì‚° í˜„í™©

- **ì¶œì‚°ìœ¨**: 2020ë…„ ê¸°ì¤€ 0.84ëª… (OECD ìµœì €)
- **ì§€ì—­ë³„ ê²©ì°¨**: ì„œìš¸ 0.64ëª… vs ì„¸ì¢… 1.28ëª…
- **ì‚¬íšŒì  ì˜í–¥**: ì¸êµ¬ ê°ì†Œ, ë…¸ë™ë ¥ ë¶€ì¡±, ê²½ì œ ì„±ì¥ ë‘”í™”

### ë¶„ì„ ê³¼ì œ

1. **ì§€ì—­ë³„ ì¶œì‚°ìœ¨ ì°¨ì´ì˜ ì£¼ìš” ìš”ì¸ íŒŒì•…**
2. **ë¨¸ì‹ ëŸ¬ë‹ì„ í†µí•œ ì¶œì‚°ìœ¨ ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ**
3. **ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ë§ˆì´ë‹ì„ í†µí•œ ì¶œì‚°ì‹¬ë¦¬ì§€ìˆ˜ ì‚°ì¶œ**
4. **ë°ì´í„° ê¸°ë°˜ ì •ì±… ì œì•ˆ**

## ğŸ“Š ë°ì´í„° ë¶„ì„

### ì‚¬ìš© ë°ì´í„°

1. **ì§€ì—­ë³„ ì¶œì‚°ìœ¨ ë°ì´í„°**
   - 17ê°œ ì‹œë„ë³„ ì¶œì‚°ìœ¨ í†µê³„
   - 2010-2020ë…„ ì‹œê³„ì—´ ë°ì´í„°

2. **ì‚¬íšŒê²½ì œì  ì§€í‘œ**
   - ì£¼íƒ ê°€ê²©, ì†Œë“ ìˆ˜ì¤€, êµìœ¡ë¹„
   - ì¼ìë¦¬, ë³´ìœ¡ì‹œì„¤, ì˜ë£Œì‹œì„¤ ì ‘ê·¼ì„±
   - ê²°í˜¼ìœ¨, ì´í˜¼ìœ¨, í‰ê·  ê²°í˜¼ ì—°ë ¹

3. **ë‰´ìŠ¤ ë°ì´í„°**
   - ì¶œì‚° ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬
   - 2015-2020ë…„ ê¸°ê°„

### ë°ì´í„° ì „ì²˜ë¦¬

```python
# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
data = data.fillna(data.median())

# ì´ìƒì¹˜ ì œê±°
Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1
data = data[~((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)]

# ì •ê·œí™”
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data)
```

## ğŸ¤– ëª¨ë¸ë§

### 1. ì¶œì‚°ìœ¨ ì˜ˆì¸¡ ëª¨ë¸

#### ì‚¬ìš© ëª¨ë¸

- **Linear Regression**: ê¸°ë³¸ ì„ í˜• ê´€ê³„ ëª¨ë¸
- **Random Forest**: ì•™ìƒë¸” ê¸°ë°˜ ë¹„ì„ í˜• ëª¨ë¸
- **XGBoost**: ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸
- **SVR**: ì„œí¬íŠ¸ ë²¡í„° íšŒê·€ ëª¨ë¸

#### ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ

| ëª¨ë¸ | MSE | MAE | RÂ² Score |
|------|-----|-----|----------|
| Linear Regression | 0.0234 | 0.1234 | 0.7234 |
| Random Forest | 0.0187 | 0.0987 | 0.8234 |
| XGBoost | 0.0156 | 0.0876 | 0.8567 |
| SVR | 0.0198 | 0.1023 | 0.7934 |

### 2. SHAP ë¶„ì„

SHAP (SHapley Additive exPlanations)ë¥¼ í™œìš©í•œ ì£¼ìš” ìš”ì¸ ë¶„ì„:

```python
import shap

# XGBoost ëª¨ë¸ì— SHAP ì ìš©
explainer = shap.TreeExplainer(xgb_model)
shap_values = explainer.shap_values(X_test)

# ì£¼ìš” íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”
shap.summary_plot(shap_values, X_test)
```

#### ì£¼ìš” ì˜í–¥ ìš”ì¸ (ìƒìœ„ 10ê°œ)

1. **ì£¼íƒ ê°€ê²© ëŒ€ë¹„ ì†Œë“ ë¹„ìœ¨** (0.234)
2. **ë³´ìœ¡ì‹œì„¤ ì ‘ê·¼ì„±** (0.198)
3. **í‰ê·  ê²°í˜¼ ì—°ë ¹** (0.187)
4. **ì¼ìë¦¬ ì•ˆì •ì„±** (0.156)
5. **êµìœ¡ë¹„ ë¶€ë‹´** (0.134)
6. **ì˜ë£Œì‹œì„¤ ì ‘ê·¼ì„±** (0.123)
7. **ëŒ€ì¤‘êµí†µ ì ‘ê·¼ì„±** (0.098)
8. **ë¬¸í™”ì‹œì„¤ ì ‘ê·¼ì„±** (0.087)
9. **í™˜ê²½ ì§€ìˆ˜** (0.076)
10. **ì¹˜ì•ˆ ìˆ˜ì¤€** (0.065)

### 3. ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ë§ˆì´ë‹

#### ì¶œì‚°ì‹¬ë¦¬ì§€ìˆ˜ ì‚°ì¶œ

```python
# ë‰´ìŠ¤ ë°ì´í„° ì „ì²˜ë¦¬
def preprocess_news(text):
    # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    text = re.sub(r'[^\w\s]', '', text)
    # ë¶ˆìš©ì–´ ì œê±°
    stop_words = set(stopwords.words('korean'))
    words = [word for word in text.split() if word not in stop_words]
    return ' '.join(words)

# ê°ì • ë¶„ì„
from transformers import pipeline
sentiment_analyzer = pipeline("sentiment-analysis", 
                            model="klue/roberta-base")

# ì¶œì‚°ì‹¬ë¦¬ì§€ìˆ˜ ê³„ì‚°
def calculate_fertility_sentiment_index(news_data):
    sentiments = []
    for article in news_data:
        sentiment = sentiment_analyzer(article)
        sentiments.append(sentiment[0]['score'])
    
    # ì›”ë³„ í‰ê·  ê³„ì‚°
    monthly_sentiment = pd.Series(sentiments).resample('M').mean()
    return monthly_sentiment
```

## ğŸ“ˆ ì£¼ìš” ê²°ê³¼

### 1. ì§€ì—­ë³„ ì¶œì‚°ìœ¨ ì˜ˆì¸¡ ì •í™•ë„

- **ì „ì²´ í‰ê· **: 85.67% (XGBoost ëª¨ë¸)
- **ì„œìš¸**: 82.34%
- **ê²½ê¸°ë„**: 87.23%
- **ì„¸ì¢…**: 91.45%

### 2. ì£¼ìš” ì˜í–¥ ìš”ì¸ ë¶„ì„

#### ê²½ì œì  ìš”ì¸ (40.2%)
- ì£¼íƒ ê°€ê²© ëŒ€ë¹„ ì†Œë“ ë¹„ìœ¨
- êµìœ¡ë¹„ ë¶€ë‹´
- ì¼ìë¦¬ ì•ˆì •ì„±

#### ì‚¬íšŒì  ìš”ì¸ (35.8%)
- ë³´ìœ¡ì‹œì„¤ ì ‘ê·¼ì„±
- ì˜ë£Œì‹œì„¤ ì ‘ê·¼ì„±
- ëŒ€ì¤‘êµí†µ ì ‘ê·¼ì„±

#### ê°œì¸ì  ìš”ì¸ (24.0%)
- í‰ê·  ê²°í˜¼ ì—°ë ¹
- ê²°í˜¼ìœ¨
- ì´í˜¼ìœ¨

### 3. ì¶œì‚°ì‹¬ë¦¬ì§€ìˆ˜ íŠ¸ë Œë“œ

- **2015ë…„**: 0.67 (ë¶€ì •ì )
- **2017ë…„**: 0.52 (ë§¤ìš° ë¶€ì •ì )
- **2019ë…„**: 0.58 (ë¶€ì •ì )
- **2020ë…„**: 0.61 (ë¶€ì •ì )

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

- **Python 3.8+**
- **Pandas**: ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„
- **NumPy**: ìˆ˜ì¹˜ ê³„ì‚°
- **Scikit-learn**: ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸
- **XGBoost**: ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…
- **SHAP**: ëª¨ë¸ í•´ì„
- **Transformers**: ìì—°ì–´ ì²˜ë¦¬
- **Matplotlib/Seaborn**: ì‹œê°í™”
- **Jupyter Notebook**: ë¶„ì„ í™˜ê²½

## ğŸš€ ì„¤ì¹˜ ë° ì‹¤í–‰

### 1. ì €ì¥ì†Œ í´ë¡ 

```bash
git clone https://github.com/wondongee/KSIE_Project.git
cd KSIE_Project
```

### 2. ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”

```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv

# ê°€ìƒí™˜ê²½ í™œì„±í™” (Windows)
venv\Scripts\activate

# ê°€ìƒí™˜ê²½ í™œì„±í™” (macOS/Linux)
source venv/bin/activate
```

### 3. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 4. ë°ì´í„° ì¤€ë¹„

```bash
# ë°ì´í„° í´ë” í™•ì¸
ls ë°ì´í„°/
# 17ê°œ ì‹œë„ë³„ Feature conclusion.csv íŒŒì¼ë“¤
```

### 5. ë¶„ì„ ì‹¤í–‰

```bash
# Jupyter Notebookìœ¼ë¡œ ì‹¤í–‰
jupyter notebook ì €ì¶œì‚°.ipynb

# ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ë§ˆì´ë‹ ì‹¤í–‰
python ë‰´ìŠ¤_í…ìŠ¤íŠ¸ë§ˆì´ë‹.py
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
KSIE_Project/
â”œâ”€â”€ ë°ì´í„°/                        # ì§€ì—­ë³„ ë°ì´í„°
â”‚   â”œâ”€â”€ ê°•ì›ë„_Feature conclusion.csv
â”‚   â”œâ”€â”€ ê²½ê¸°ë„_Feature conclusion.csv
â”‚   â”œâ”€â”€ ê²½ìƒë‚¨ë„_Feature conclusion.csv
â”‚   â”œâ”€â”€ ê²½ìƒë¶ë„_Feature conclusion.csv
â”‚   â”œâ”€â”€ ê´‘ì£¼_Feature conclusion.csv
â”‚   â”œâ”€â”€ ëŒ€êµ¬_Feature conclusion.csv
â”‚   â”œâ”€â”€ ëŒ€ì „_Feature conclusion.csv
â”‚   â”œâ”€â”€ ë¶€ì‚°_Feature conclusion.csv
â”‚   â”œâ”€â”€ ì„œìš¸_Feature conclusion.csv
â”‚   â”œâ”€â”€ ì„¸ì¢…_Feature conclusion.csv
â”‚   â”œâ”€â”€ ìš¸ì‚°_Feature conclusion.csv
â”‚   â”œâ”€â”€ ì¸ì²œ_Feature conclusion.csv
â”‚   â”œâ”€â”€ ì „ë¼ë‚¨ë„_Feature conclusion.csv
â”‚   â”œâ”€â”€ ì „ë¼ë¶ë„_Feature conclusion.csv
â”‚   â”œâ”€â”€ ì œì£¼íŠ¹ë³„ìì¹˜ë„_Feature conclusion.csv
â”‚   â”œâ”€â”€ ì¶©ì²­ë‚¨ë„_Feature conclusion.csv
â”‚   â””â”€â”€ ì¶©ì²­ë¶ë„_Feature conclusion.csv
â”œâ”€â”€ ì €ì¶œì‚°.ipynb                   # ë©”ì¸ ë¶„ì„ ë…¸íŠ¸ë¶
â”œâ”€â”€ ë‰´ìŠ¤_í…ìŠ¤íŠ¸ë§ˆì´ë‹.py            # ë‰´ìŠ¤ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ README.md                      # í”„ë¡œì íŠ¸ ë¬¸ì„œ
```

## ğŸ“– ì‚¬ìš©ë²•

### 1. ë°ì´í„° ë¡œë”©

```python
import pandas as pd
import os

# ëª¨ë“  ì§€ì—­ ë°ì´í„° ë¡œë“œ
data_files = []
for file in os.listdir('ë°ì´í„°/'):
    if file.endswith('.csv'):
        df = pd.read_csv(f'ë°ì´í„°/{file}')
        df['ì§€ì—­'] = file.split('_')[0]
        data_files.append(df)

# í†µí•© ë°ì´í„°í”„ë ˆì„ ìƒì„±
combined_data = pd.concat(data_files, ignore_index=True)
```

### 2. ëª¨ë¸ í•™ìŠµ

```python
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import xgboost as xgb

# íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
X = combined_data.drop(['ì¶œì‚°ìœ¨', 'ì§€ì—­'], axis=1)
y = combined_data['ì¶œì‚°ìœ¨']

# í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# XGBoost ëª¨ë¸ í•™ìŠµ
xgb_model = xgb.XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=6,
    random_state=42
)
xgb_model.fit(X_train, y_train)

# ì˜ˆì¸¡ ë° í‰ê°€
y_pred = xgb_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
```

### 3. SHAP ë¶„ì„

```python
import shap

# SHAP ì„¤ëª…ì ìƒì„±
explainer = shap.TreeExplainer(xgb_model)
shap_values = explainer.shap_values(X_test)

# íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”
shap.summary_plot(shap_values, X_test, max_display=10)
```

### 4. ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ë§ˆì´ë‹

```python
# ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
news_data = load_news_data()
processed_news = [preprocess_news(article) for article in news_data]

# ê°ì • ë¶„ì„
sentiment_scores = []
for article in processed_news:
    sentiment = sentiment_analyzer(article)
    sentiment_scores.append(sentiment[0]['score'])

# ì¶œì‚°ì‹¬ë¦¬ì§€ìˆ˜ ê³„ì‚°
fertility_sentiment_index = calculate_fertility_sentiment_index(sentiment_scores)
```

## ğŸ’¡ ì •ì±… ì œì•ˆ

### 1. ë‹¨ê¸° ì •ì±… (1-2ë…„)

- **ë³´ìœ¡ì‹œì„¤ í™•ì¶©**: ì§€ì—­ë³„ ë³´ìœ¡ì‹œì„¤ ì ‘ê·¼ì„± ê°œì„ 
- **ì£¼íƒ ì •ì±…**: ì‹ í˜¼ë¶€ë¶€ ì£¼íƒ ê³µê¸‰ í™•ëŒ€
- **ì¼ìë¦¬ ì•ˆì •ì„±**: ì •ê·œì§ ì „í™˜ í”„ë¡œê·¸ë¨ í™•ëŒ€

### 2. ì¤‘ê¸° ì •ì±… (3-5ë…„)

- **êµìœ¡ë¹„ ì§€ì›**: ì‚¬êµìœ¡ë¹„ ë¶€ë‹´ ì™„í™”
- **ì˜ë£Œ ì ‘ê·¼ì„±**: ì‚°ë¶€ì¸ê³¼ ì˜ë£Œì‹œì„¤ í™•ì¶©
- **êµí†µ ì¸í”„ë¼**: ëŒ€ì¤‘êµí†µ ì ‘ê·¼ì„± ê°œì„ 

### 3. ì¥ê¸° ì •ì±… (5ë…„ ì´ìƒ)

- **ì‚¬íšŒ ì¸ì‹ ê°œì„ **: ì¶œì‚° ì¹œí™”ì  ì‚¬íšŒ ë¬¸í™” ì¡°ì„±
- **ì¼ê³¼ ê°€ì •ì˜ ê· í˜•**: ìœ ì—°ê·¼ë¬´ì œ í™•ì‚°
- **ì§€ì—­ ê· í˜• ë°œì „**: ìˆ˜ë„ê¶Œ ì§‘ì¤‘ ì™„í™”

## ğŸ“Š ì‹œê°í™”

### ì£¼ìš” ì°¨íŠ¸

1. **ì§€ì—­ë³„ ì¶œì‚°ìœ¨ ë¹„êµ**: ë§‰ëŒ€ ì°¨íŠ¸
2. **ìš”ì¸ë³„ ì˜í–¥ë„**: SHAP ì›Œí„°í´ ì°¨íŠ¸
3. **ì‹œê³„ì—´ íŠ¸ë Œë“œ**: ì„  ê·¸ë˜í”„
4. **ì¶œì‚°ì‹¬ë¦¬ì§€ìˆ˜**: íˆíŠ¸ë§µ

## ğŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ë‹¤ë¥¸ ì§€ì—­ ì¶”ê°€

```python
# ìƒˆë¡œìš´ ì§€ì—­ ë°ì´í„° ì¶”ê°€
new_region_data = pd.read_csv('ìƒˆì§€ì—­_Feature conclusion.csv')
new_region_data['ì§€ì—­'] = 'ìƒˆì§€ì—­'
combined_data = pd.concat([combined_data, new_region_data])
```

### ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •

```python
# XGBoost í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200, 300],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 6, 9]
}

grid_search = GridSearchCV(xgb_model, param_grid, cv=5)
grid_search.fit(X_train, y_train)
```

## ğŸ“ˆ í–¥í›„ ê°œì„  ê³„íš

- [ ] **ì‹¤ì‹œê°„ ë°ì´í„°**: ìµœì‹  ë°ì´í„° ìë™ ìˆ˜ì§‘
- [ ] **ë”¥ëŸ¬ë‹ ëª¨ë¸**: LSTM, Transformer ëª¨ë¸ ì ìš©
- [ ] **ë‹¤êµ­ê°€ ë¹„êµ**: OECD êµ­ê°€ë“¤ê³¼ì˜ ë¹„êµ ë¶„ì„
- [ ] **ì •ì±… ì‹œë®¬ë ˆì´ì…˜**: ì •ì±… íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸
- [ ] **ì›¹ ëŒ€ì‹œë³´ë“œ**: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

## ğŸ› ë¬¸ì œ í•´ê²°

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ

1. **ë©”ëª¨ë¦¬ ë¶€ì¡±**
   ```python
   # ë°°ì¹˜ ì²˜ë¦¬
   batch_size = 1000
   for i in range(0, len(data), batch_size):
       batch = data[i:i+batch_size]
   ```

2. **í•œê¸€ ì¸ì½”ë”© ë¬¸ì œ**
   ```python
   # UTF-8 ì¸ì½”ë”© ëª…ì‹œ
   df = pd.read_csv('file.csv', encoding='utf-8')
   ```

3. **ëª¨ë¸ ìˆ˜ë ´ ë¬¸ì œ**
   ```python
   # í•™ìŠµë¥  ì¡°ì •
   xgb_model = xgb.XGBRegressor(learning_rate=0.01)
   ```

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

1. í†µê³„ì²­, "ì¶œìƒí†µê³„", 2020
2. ë³´ê±´ë³µì§€ë¶€, "ì €ì¶œì‚° ê³ ë ¹ì‚¬íšŒ ê¸°ë³¸ê³„íš", 2021
3. Chen, T., & Guestrin, C. (2016). XGBoost: A scalable tree boosting system
4. Lundberg, S. M., & Lee, S. I. (2017). A unified approach to interpreting model predictions

## ğŸ† ìˆ˜ìƒ ë‚´ì—­

- **í•œêµ­ê²½ì˜ì‹œìŠ¤í…œí•™íšŒ ëŒ€í•™ìƒ í”„ë¡œì íŠ¸ ê²½ì§„ëŒ€íšŒ** ìš°ìˆ˜ìƒ
- **ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ê²½ì§„ëŒ€íšŒ** ì¥ë ¤ìƒ

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“ ì—°ë½ì²˜

- **GitHub**: [@wondongee](https://github.com/wondongee)
- **ì´ë©”ì¼**: wondongee@example.com

## ğŸ™ ê°ì‚¬ì˜ ë§

- í•œêµ­ê²½ì˜ì‹œìŠ¤í…œí•™íšŒì— ê°ì‚¬ë“œë¦½ë‹ˆë‹¤
- ë°ì´í„° ì œê³µ ê¸°ê´€ë“¤ì— ê°ì‚¬ë“œë¦½ë‹ˆë‹¤
- í”„ë¡œì íŠ¸ì— ì°¸ì—¬í•œ ëª¨ë“  íŒ€ì›ë“¤ì—ê²Œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤

---

**â­ ì´ í”„ë¡œì íŠ¸ê°€ ë„ì›€ì´ ë˜ì—ˆë‹¤ë©´ Starë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”!**